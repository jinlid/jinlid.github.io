<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>第四章--调优艺术</title>
      <link href="/2026/4.diao-you-yi-zhu/"/>
      <url>/2026/4.diao-you-yi-zhu/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h2 id="4-1-索引术"><a href="#4-1-索引术" class="headerlink" title="4.1 索引术"></a>4.1 索引术</h2><h3 id="4-1-1-常见索引结构"><a href="#4-1-1-常见索引结构" class="headerlink" title="4.1.1 常见索引结构"></a>4.1.1 常见索引结构</h3><p>在数据库表上合理创建索引，可显著提升查询执行效率；若未创建索引，查询过程可能消耗大量时间。需特别说明的是，在特定场景下，全表扫描的效率可能高于索引扫描，相关细节将在本节后续内容中进一步探讨。</p><p>Panweidb 提供多种索引类型及丰富的创建方式。本节将简要介绍 Panweidb 支持的常见索引类型，并结合具体示例，详细说明各类索引的特性与使用方法，为索引的合理选择与应用提供参考。</p><h4 id="B-Tree-Index（B树索引）"><a href="#B-Tree-Index（B树索引）" class="headerlink" title="B-Tree Index（B树索引）"></a>B-Tree Index（B树索引）</h4><p>B-Tree索引是 Panweidb 中的默认索引类型。当执行“CREATE INDEX”语句且未指定索引类型时，系统将自动创建 B树索引。该索引适用于具有排序特性的数据，可高效处理相等查询（如“=”）和范围查询（如“&gt;”“&lt;”“BETWEEN”等）。创建 B树索引的语法如下：</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> name <span class="token keyword">ON</span> <span class="token keyword">table</span> <span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 或明确指定索引类型</span><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> name <span class="token keyword">ON</span> <span class="token keyword">table</span> <span class="token keyword">USING</span> <span class="token keyword">BTREE</span> <span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="Hash-Index（哈希索引）"><a href="#Hash-Index（哈希索引）" class="headerlink" title="Hash Index（哈希索引）"></a>Hash Index（哈希索引）</h4><p>哈希索引仅支持相等运算符（<code>=</code>），仅能用于匹配查询条件完全一致的数据。在部分业务场景中，其性能表现优于 B 树索引，同时具备更高的空间利用率。经过多轮深度优化后，哈希索引的查找速度得到大幅提升，成为一款专用索引，适用于以相等比较为核心查询逻辑的业务场景。创建哈希索引的语法如下：</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> name <span class="token keyword">ON</span> <span class="token keyword">table</span> <span class="token keyword">USING</span> <span class="token keyword">HASH</span> <span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Gist-Index（广义搜索树索引）"><a href="#Gist-Index（广义搜索树索引）" class="headerlink" title="Gist Index（广义搜索树索引）"></a>Gist Index（广义搜索树索引）</h4><p>广义搜索树（Gist）索引适用于索引逻辑复杂的数据场景，尤其是当查询需求超出简单的相等或范围比较（如相邻查找、模式匹配等）时，其优势更为明显。典型应用场景包括几何数据（如点、线、面的空间查询）、网络地址比较、全文搜索等。</p><p>创建 Gist 索引的语法如下：</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> name <span class="token keyword">ON</span> <span class="token keyword">table</span> <span class="token keyword">USING</span> gist <span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="SP-Gist-Index"><a href="#SP-Gist-Index" class="headerlink" title="SP-Gist Index"></a>SP-Gist Index</h4><p>SP-Gist（Space-Partitioned GiST，空间分区广义搜索树）是 Gist 索引的扩展，支持分区搜索树结构。该索引可用于开发多种非平衡数据结构，例如四叉树、kd树、基数树（字典树）等。此类数据结构的核心特点是反复将搜索空间划分为大小可不等的分区，对于与分区规则高度匹配的搜索场景，可实现极高的查询效率。</p><p>SP-Gist 索引适用于具有天然分区特性的数据查询，例如地理位置数据的分级检索、字典类数据的前缀匹配等场景。</p><h4 id="Gin-Index"><a href="#Gin-Index" class="headerlink" title="Gin Index"></a>Gin Index</h4><p>广义倒排索引（Gin）主要用于索引单列中包含多个元素的数据类型，例如数组（array）、JSON 文档（jsonb 类型）、文本搜索文档（tsvector 类型）等。其核心优势在于可高效检索多元素字段中的单个或多个目标元素，适用于多值数据的快速匹配查询。</p><p>创建 Gin 索引的语法如下：</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> name <span class="token keyword">ON</span> <span class="token keyword">table</span> <span class="token keyword">USING</span> gin <span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述内容详细介绍了 Panweidb支持的常见索引结构。接下来，将重点阐述索引的核心特性，这些特性可用于进一步调整和优化索引性能，满足不同业务场景的查询需求。</p><h4 id="多列索引"><a href="#多列索引" class="headerlink" title="多列索引"></a>多列索引</h4><p>Panweidb 支持在多个列上创建联合索引（即多列索引），但最多支持 32 个列的组合，且仅 Btree、Gist、Gin索引类型支持多列索引。多列索引的查询效率与列的排序顺序密切相关，通常应将查询频率最高、选择性最强的列置于索引列的最前面。以下为多列索引的创建示例：</p><p> <img src="/medias/image/image-20260129095148633.png" alt="image-20260129095148633"></p><h4 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h4><p>唯一索引的核心作用是强制索引列（或列组合）中的值具有唯一性，避免出现重复数据。在 Panweidb 中，可在单个列或多个列上创建唯一索引；若为多列创建唯一索引，则通过列值的组合来确保唯一性。需注意的是，仅B树索引支持声明为唯一索引。 <img src="/medias/image/image-20260129095457006.png" alt="image-20260129095457006"></p><p>多列唯一索引的创建示例如下：</p><p> <img src="/medias/image/image-20260129095525701.png" alt="image-20260129095525701"></p><p>需特别说明的是，NULL 值不被视为相等值，因此在唯一索引列中可插入多个 NULL 值，不会触发索引唯一性违规。</p><p>当为表列声明唯一约束（UNIQUE CONSTRAINT）或主键约束（PRIMARY KEY）时，Panweidb 会自动为该列（或列组合）创建唯一索引，无需手动创建。相关示例如下：</p><p> <img src="/medias/image/image-20260129095621897.png" alt="image-20260129095621897"></p><h4 id="表达式索引"><a href="#表达式索引" class="headerlink" title="表达式索引"></a><strong>表达式索引</strong></h4><p>在 Panweidb 中，可基于表中一列或多列的函数计算结果、标量表达式结果创建索引，此类索引称为表达式索引。由于表达式的计算结果已预先存储在索引中，查询时无需实时计算，可显著提升数据访问效率；但与此同时，数据的插入、更新操作会因需要重新计算表达式并同步更新索引，导致操作代价增加。</p><p>表达式索引适用于查询中频繁使用固定表达式的场景，例如对字符串字段的小写转换查询、日期字段的格式化查询等。以下为表达式索引的示例：</p><p> <img src="/medias/image/image-20260129095737813.png" alt="image-20260129095737813"></p><p>表达式索引的创建与查询效果验证示例如下：</p><p> <img src="/medias/image/image-20260129095856315.png" alt="image-20260129095856315"></p><h4 id="部分索引"><a href="#部分索引" class="headerlink" title="部分索引"></a><strong>部分索引</strong></h4><p>部分索引（Partial Index）是指仅对表中满足特定条件的行建立索引，而非对整个表的数据建立索引。此类索引通过 WHERE 子句指定过滤条件，仅包含符合条件的行数据，因此索引体积远小于全表索引，数据访问速度更快，同时可节省存储空间。</p><p>部分索引适用于查询仅针对表中部分数据的场景，例如仅对“状态为有效”的订单数据建立索引、仅对“金额大于 1000”的交易数据建立索引等。以下为部分索引的示例：</p><p> <img src="/medias/image/image-20260129100018216.png" alt="image-20260129100018216"></p><p>部分索引的创建示例如下：</p><p> <img src="/medias/image/image-20260129100058098.png" alt="image-20260129100058098"></p><h4 id="仅索引扫描"><a href="#仅索引扫描" class="headerlink" title="仅索引扫描"></a><strong>仅索引扫描</strong></h4><p>通常情况下，索引与表数据分开存储，查询时需先通过索引定位数据行的位置，再从表文件中读取具体数据，该过程称为“索引扫描”。而仅索引扫描（Index-Only Scan）是一种优化的扫描方式：若查询语句所需的所有字段均为索引列（即查询字段完全包含在索引中），则无需访问表文件，可直接从索引中读取所需数据，从而进一步提升查询性能。</p><p> <img src="/medias/image/image-20260129100309341.png" alt="image-20260129100309341"></p><p>需注意的是，若查询语句中包含不属于索引列的字段，则无法使用仅索引扫描，系统将自动切换为普通索引扫描或全表扫描。示例如下：</p><p> <img src="/medias/image/image-20260129100340789.png" alt="image-20260129100340789"></p><p>目前，仅 B-tree、Gist、SP-Gist 三种索引类型支持仅索引扫描，Gin、Hash 索引暂不支持该特性。</p><h4 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h4><p>覆盖索引与仅索引扫描的原理相近，且适用场景更为灵活。当查询所需字段超出索引列范围，但业务仍希望避免访问主表、仅通过索引获取全部数据时，可通过 PanWeiDB 支持的INCLUDE 子句创建覆盖索引。需注意的是，该类型索引仅由 ubtree 索引支持，且仅适配 Ustore 存储引擎；其可在索引中附加非索引列信息，让查询语句所需的所有字段均能直接从索引中读取，以此实现类仅索引扫描的查询优化效果。</p><p> <img src="/medias/image/image-20260129101032668.png" alt="image-20260129101032668"></p><p>需注意的是，若创建索引时未指定 INCLUDE 子句，且查询字段超出索引列范围，则系统无法使用仅索引扫描，将自动采用普通索引扫描。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>Panweidb 提供多种类型的索引，每种索引均有其独特的适用场景和性能特性。能够灵活选择索引类型是提升数据库查询性能的关键，但该能力需谨慎使用——若选择错误的索引类型、创建不合理的索引（如过度创建索引、索引列选择不当等），不仅无法提升性能，反而可能降低数据库效率。</p><p>索引的核心作用是加速数据检索，但数据库系统需在后台持续执行额外工作，确保索引与表中更新的数据保持同步（如插入、更新、删除数据时同步更新索引），这可能导致索引膨胀、磁盘空间占用增加、写入性能下降等问题。因此，在创建索引时，需结合业务场景，全面考量数据检索需求与数据更新频率，合理规划索引的类型、数量和结构，实现检索性能与写入性能的平衡。</p><h3 id="4-1-2-索引适用场景说明"><a href="#4-1-2-索引适用场景说明" class="headerlink" title="4.1.2 索引适用场景说明"></a>4.1.2 索引适用场景说明</h3><p>结合 4.1.1 节介绍的索引类型特性，以下明确各类索引的核心适用场景，为业务实践中的索引选择提供精准参考：</p><h4 id="B-Tree-索引"><a href="#B-Tree-索引" class="headerlink" title="B-Tree 索引"></a>B-Tree 索引</h4><p>核心适用场景：适用于大多数常规查询场景，尤其是具有排序需求、相等查询或范围查询的场景，是业务中最常用的索引类型。</p><ul><li>典型场景：用户 ID 检索（相等查询）、订单时间范围查询（范围查询）、商品价格排序查询（排序+范围查询）、用户姓名模糊匹配（前缀匹配，如“LIKE ‘张%’”）；</li><li>适配字段类型：数值型（int、bigint、numeric 等）、字符串型（varchar、text 等）、日期时间型（date、timestamp 等）等具有天然排序特性的字段；</li><li>不适用于：多元素字段（如数组、jsonb）、空间几何字段、非前缀匹配的模糊查询（如“LIKE ‘%张%’”）。</li></ul><h4 id="Hash-索引"><a href="#Hash-索引" class="headerlink" title="Hash 索引"></a>Hash 索引</h4><p>核心适用场景：仅适用于“完全相等”的查询场景，且数据更新频率较低、查询频率极高，追求极致的相等匹配效率。</p><ul><li><p>典型场景：字典表精确匹配（如根据字典编码查询字典名称）、用户账号精确检索（如根据账号查询用户信息）、枚举值精确匹配（如根据状态码查询状态描述）；</p></li><li><p>适配字段类型：字符串型、数值型等可进行相等比较的简单字段；</p></li><li><p>不适用于：范围查询、排序查询、模糊查询、多元素字段查询，以及数据写入频繁的场景（写入时索引更新代价较高）。</p></li><li><p>由于各种原因，panwei3.2.1版本之前的哈希索引不被鼓励使用，例如：</p><ul><li>不记录 WAL（Write-Ahead Logging，预写日志），导致数据库崩溃后索引不可靠，可能出现数据不一致；</li><li>由于不记录 WAL，无法用于流复制场景，无法实现主备节点间的索引同步；</li><li>性能表现不佳，索引构建耗时较长（具体耗时取决于表的数据量）。</li></ul><p>不过从panwei3.2.1开始，上述问题已得到全面解决。当前版本的哈希索引具备安全性，可正常同步至备机，</p></li></ul><h4 id="Gist-索引"><a href="#Gist-索引" class="headerlink" title="Gist 索引"></a>Gist 索引</h4><p>核心适用场景：复杂数据类型的查询，尤其是空间数据、全文搜索、模式匹配等超出简单相等/范围比较的场景。</p><ul><li>典型场景：地理位置查询（如查询某一区域内的店铺、两点间距离查询）、全文搜索（如文章内容关键词检索）、网络地址匹配（如 IP 地址段查询）、几何图形匹配（如判断两个图形是否相交）；</li><li>适配字段类型：几何类型（point、line、polygon 等）、网络地址类型（inet、cidr 等）、全文搜索类型（tsvector 等）；</li><li>不适用于：简单字段的常规查询（效率低于 B-Tree 索引）、多元素字段查询。</li></ul><h4 id="SP-Gist-索引"><a href="#SP-Gist-索引" class="headerlink" title="SP-Gist 索引"></a>SP-Gist 索引</h4><p>核心适用场景：具有天然分区特性的数据查询，尤其是非平衡数据结构的检索，追求分区匹配的高效性。</p><ul><li>典型场景：地理位置分级检索（如先按省份分区、再按城市检索）、字典类数据前缀匹配（如拼音首字母检索、英文前缀检索）、kd树/四叉树相关的空间检索；</li><li>适配字段类型：字符串型、几何类型、数值型等可进行分区划分的字段；</li><li>不适用于：无分区特性的常规查询、相等查询（效率低于 B-Tree、Hash 索引）。</li></ul><h4 id="Gin-索引"><a href="#Gin-索引" class="headerlink" title="Gin 索引"></a>Gin 索引</h4><p>核心适用场景：多元素字段的检索，即单个字段包含多个值，需查询该字段中包含某一/多个目标值的场景。</p><ul><li>典型场景：数组字段查询（如查询包含某一标签的文章，标签字段为数组类型）、jsonb 字段查询（如查询某一属性值的 JSON 文档）、多值枚举字段查询（如查询包含多个兴趣爱好的用户）；</li><li>适配字段类型：数组（array）、jsonb、tsvector 等多元素字段；</li><li>不适用于：简单字段的常规查询、范围查询、排序查询。</li></ul><h4 id="特殊索引（多列、唯一、表达式、部分、覆盖）适用场景"><a href="#特殊索引（多列、唯一、表达式、部分、覆盖）适用场景" class="headerlink" title="特殊索引（多列、唯一、表达式、部分、覆盖）适用场景"></a>特殊索引（多列、唯一、表达式、部分、覆盖）适用场景</h4><ul><li>多列索引：适用于查询频繁包含多个字段组合的场景，如“用户 ID + 订单状态”联合查询、“商品分类 + 价格范围”联合查询；需注意列的排序顺序，将查询频率最高、选择性最强的列置于前面。</li><li>唯一索引：适用于需保证数据唯一性的场景，如用户账号、身份证号、订单编号等字段，可通过唯一索引避免重复数据，同时提升查询效率；主键约束自动创建唯一索引，无需手动重复创建。</li><li>表达式索引：适用于查询频繁使用固定表达式的场景，如“小写用户名查询”（LOWER(username) = ‘test’）、“日期格式化查询”（TO_CHAR(create_time, ‘YYYY-MM-DD’) = ‘2024-01-01’），可避免查询时实时计算表达式。</li><li>部分索引：适用于查询仅针对表中部分数据的场景，如仅查询“有效状态”的订单、仅查询“金额大于 1000”的交易，可减少索引体积、提升查询效率、节省存储空间。</li><li>覆盖索引：适用于查询字段超出索引列，但希望避免访问主表的场景，如索引列为“用户 ID”，但查询需返回“用户 ID + 用户名”，可通过 INCLUDE (username) 创建覆盖索引，实现仅索引扫描。</li></ul><h3 id="4-1-2-索引使用注意事项"><a href="#4-1-2-索引使用注意事项" class="headerlink" title="4.1.2 索引使用注意事项"></a>4.1.2 索引使用注意事项</h3><p>索引是提升数据库查询性能的重要手段，但不合理的使用会带来诸多问题，需重点关注以下注意事项，实现索引的高效应用：</p><h4 id="1-避免过度创建索引"><a href="#1-避免过度创建索引" class="headerlink" title="1. 避免过度创建索引"></a>1. 避免过度创建索引</h4><p>索引并非越多越好，每创建一个索引，都会增加数据库的写入负担（插入、更新、删除数据时，需同步更新所有相关索引），同时会占用额外的磁盘空间，可能导致索引膨胀。</p><p>建议：根据业务查询需求，仅创建必要的索引；对于写入频繁、查询极少的表（如日志表、临时表），尽量不创建索引；避免为同一查询场景创建多个功能重复的索引（如同时创建 B-Tree 索引和 Hash 索引用于相等查询）。</p><h4 id="2-合理选择索引列"><a href="#2-合理选择索引列" class="headerlink" title="2. 合理选择索引列"></a>2. 合理选择索引列</h4><ol><li>优先选择选择性高的字段作为索引列：选择性是指字段中唯一值的比例（唯一值越多，选择性越高），如用户 ID、身份证号（选择性接近 100%），适合作为索引列；而性别、状态等字段（选择性极低，通常仅 2-3 个唯一值），不适合作为单独的索引列（索引效率极低，甚至不如全表扫描）。</li><li>避免选择过长的字段作为索引列：索引列的长度越长，索引体积越大，查询时的 I/O 开销越高，索引构建和更新的速度也会变慢。建议：对于字符串字段，可选择前缀索引（如取 varchar(100) 字段的前 20 个字符作为索引列），平衡索引效率和空间占用；优先选择短字段（如 int、smallint 等）作为索引列。</li><li>避免使用 NULL 值过多的字段作为索引列：虽然 Panweidb 支持 NULL 值的索引，但 NULL 值过多的字段（如某字段 90% 以上的值为 NULL），索引的选择性极低，查询效率不佳；同时，NULL 值会增加索引的存储空间。</li><li>多列索引需注意列的排序顺序：多列索引的查询效率与列的顺序密切相关，应将查询频率最高、选择性最强的列置于最前面，后续列的选择性依次降低。例如，查询频繁为“WHERE user_id = ? AND order_status = ?”，应创建 (user_id, order_status) 的多列索引，而非 (order_status, user_id)。</li></ol><h4 id="3-关注索引扫描效率，避免索引失效"><a href="#3-关注索引扫描效率，避免索引失效" class="headerlink" title="3. 关注索引扫描效率，避免索引失效"></a>3. 关注索引扫描效率，避免索引失效</h4><p>即使创建了索引，数据库也可能选择全表扫描（索引失效），导致索引无法发挥作用，需避免以下常见场景：</p><ol><li>查询条件中使用函数或表达式操作索引列：如“WHERE LOWER(username) = ‘test’”（若 username 为索引列，函数操作会导致索引失效），此时应创建表达式索引（LOWER(username)），而非普通索引。</li><li>查询条件中使用不等于（!=、&lt;&gt;）、NOT IN、IS NOT NULL 等操作符：此类操作符可能导致数据库无法使用索引，优先选择全表扫描；若需实现类似查询，可通过业务逻辑优化（如用范围查询替代 NOT IN）。</li><li>模糊查询使用前缀通配符（如“LIKE ‘%张%’”）：此类查询无法使用 B-Tree 索引（仅支持前缀匹配，如“LIKE ‘张%’”）；若需实现后缀或任意位置的模糊查询，可使用 Gist 全文搜索索引。</li><li>查询条件中包含 OR 连接的非索引列：如“WHERE user_id = ? OR age = ?”，若 age 未创建索引，即使 user_id 有索引，数据库也可能选择全表扫描；建议将 OR 拆分为多个 AND 查询，或为所有相关列创建索引。</li><li>数据量过小的表：对于小表（如数据量不足 1 万行），全表扫描的效率可能高于索引扫描（索引查询需额外的 I/O 开销），此时数据库会自动选择全表扫描，索引无法发挥作用，无需创建索引。</li></ol><h4 id="4-关注索引维护与优化"><a href="#4-关注索引维护与优化" class="headerlink" title="4. 关注索引维护与优化"></a>4. 关注索引维护与优化</h4><ol><li>定期清理无效索引：业务迭代过程中，部分查询场景可能被淘汰，对应的索引会成为无效索引（不再被任何查询使用），需定期排查并删除无效索引，释放磁盘空间、减轻写入负担。</li><li>监控索引膨胀：频繁的插入、更新、删除操作会导致索引膨胀（索引中出现大量空洞，空间利用率降低），表现为索引体积过大、查询效率下降。建议定期使用 REINDEX 命令重建索引，清理空洞、优化索引结构；对于大数据量表，可使用 CONCURRENTLY 选项（如 REINDEX INDEX CONCURRENTLY idx_name），避免重建索引时锁定表，影响业务正常运行。</li><li>合理设置索引相关参数：Panweidb 提供了多个与索引相关的参数（如 shared_buffers、work_mem 等），可根据服务器硬件配置、业务场景调整参数，优化索引的构建和查询效率；例如，增大 work_mem 可提升索引构建速度，增大 shared_buffers 可提升索引查询的缓存命中率。</li></ol><h4 id="5-特殊场景索引使用建议"><a href="#5-特殊场景索引使用建议" class="headerlink" title="5. 特殊场景索引使用建议"></a>5. 特殊场景索引使用建议</h4><ol><li>大数据量写入场景（如日志采集、数据同步）：尽量减少索引数量（仅保留核心查询所需索引），避免索引更新占用过多资源；可采用批量写入、延迟创建索引等方式，降低写入压力。</li><li>只读/读写比例极高的场景（如报表查询、数据统计）：可适当增加索引数量，优化查询效率；对于频繁查询的复杂语句，可创建覆盖索引、表达式索引，进一步提升性能。</li></ol><h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>索引的选择与使用需紧密结合业务场景，核心是“适配查询需求、平衡检索与写入性能”。不同类型的索引对应不同的查询场景，需根据字段特性、查询方式、数据量大小，选择合适的索引类型和结构；同时，需规避过度创建索引、索引列选择不当、索引失效等问题，定期进行索引维护与优化，确保索引持续发挥高效作用，提升 Panweidb 数据库的整体性能。</p><h2 id="4-2-缓存术"><a href="#4-2-缓存术" class="headerlink" title="4.2 缓存术"></a>4.2 缓存术</h2><p>4.2.1 双缓存介绍</p><p>最佳实践介绍</p><p>注意事项</p><p>4.2.2 线程池最佳实践</p><p>线程池介绍<br>最佳实践介绍<br>注意事项</p><p>4.2.3 MOT内存表介绍</p><h2 id="4-3-压缩术"><a href="#4-3-压缩术" class="headerlink" title="4.3 压缩术"></a>4.3 压缩术</h2><p>常见压缩方法</p><p>硬件压缩ZFS/软件压缩有很多种<br>LZ4、ZSTD、punch hole打洞反还</p><p>优劣势对比</p><p>注意事项</p><h2 id="4-4-批量处理术"><a href="#4-4-批量处理术" class="headerlink" title="4.4 批量处理术"></a>4.4 批量处理术</h2><h3 id="4-4-1-业务批量插入最佳实践"><a href="#4-4-1-业务批量插入最佳实践" class="headerlink" title="4.4.1 业务批量插入最佳实践"></a>4.4.1 业务批量插入最佳实践</h3><p>在 PanWeDB 数据库运维中，常需通过单个或最少步骤完成海量数据的导入操作，即批量数据导入，其数据源多为单个或多个大文件。若未采用针对性优化方案，该过程会因各类性能瓶颈导致加载速度极慢，难以满足业务需求。</p><p>造成 PanWeDB 批量插入性能低下的核心原因包括：索引的实时更新开销、触发器的逐行触发执行、外键约束的有效性校验、GUID 主键的生成成本，以及预写日志（WAL）的写入机制等，这些因素会单独或叠加成为数据加载的关键阻碍。</p><p>常规插入过程中，典型的非批量插入操作遵循“准备语句-绑定参数-发送请求-确认插入”的重复模式，每行数据都需要单独循环执行，网络通信和数据库处理的开销会随数据量急剧增加。而批量插入通过整合多组插入操作，可大幅降低这类冗余开销，是海量数据导入的最优选择。</p><h4 id="JDBC-批处理工作原理"><a href="#JDBC-批处理工作原理" class="headerlink" title="JDBC 批处理工作原理"></a>JDBC 批处理工作原理</h4><p>JDBC 批处理的核心是将多个 INSERT 操作分组整合，减少客户端与数据库的网络往返次数，降低语句解析和事务提交的开销。其工作逻辑为：JDBC 驱动在内存中收集多组插入参数，不逐行执行插入，待累积到指定批量大小或手动触发时，将整批操作作为一个请求发送至数据库，实现一次性高效处理。</p><p>需重点注意，PanWeDB 支持开启 <code>reWriteBatchedInserts=true</code> 驱动参数，开启后驱动会自动将批处理操作重写为单条多值 INSERT 语句，进一步提升数据库执行效率。</p><p>实际应用中，建议将批量大小控制在 100-200 行，平衡性能与内存占用——批量过小无法有效降低开销，过大则可能导致客户端内存溢出或数据库请求拥堵；同时可结合事务控制，在单个事务中完成多批插入，既保证数据一致性，又进一步减少事务提交开销。JDBC 批处理适用于程序动态生成数据源的场景，常与后续最佳实践组合使用以最大化性能。</p><h3 id="4-4-2-业务批量插入最佳实践-insert"><a href="#4-4-2-业务批量插入最佳实践-insert" class="headerlink" title="4.4.2 业务批量插入最佳实践(insert)"></a>4.4.2 业务批量插入最佳实践(insert)</h3><p>结合 PanWeDB 原生特性与 JDBC 批处理能力，批量插入的核心优化思路是“导入前禁用非必要开销、导入中高效执行、导入后恢复校验”，以下是经过生产环境验证的核心最佳实践，可根据实际场景组合使用，实现性能最大化。</p><h5 id="1-创建目标表为-UNLOGGED-模式"><a href="#1-创建目标表为-UNLOGGED-模式" class="headerlink" title="1 创建目标表为 UNLOGGED 模式"></a>1 创建目标表为 UNLOGGED 模式</h5><p>UNLOGGED 表可显著提高数据导入速度，核心是跳过预写日志（WAL）的写入操作，适配快速大量插入数据的场景。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> UNLOGGED <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token punctuation">(</span>    <span class="token comment" spellcheck="true">-- 表字段定义，示例：</span>    id <span class="token keyword">SERIAL</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span><span class="token punctuation">,</span>    name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    create_time <span class="token keyword">TIMESTAMP</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>重要注意事项</strong>：UNLOGGED 表不支持流复制，主备集群中数据不会同步到备节点，暂时丧失高可用；若加载过程中数据库崩溃、服务器异常，数据无法恢复，重启后 PanWeDB 会自动截断该表，需提前做好风险评估，建议在业务低峰期执行。</p><h5 id="2-删除索引后重新创建"><a href="#2-删除索引后重新创建" class="headerlink" title="2. 删除索引后重新创建"></a>2. 删除索引后重新创建</h5><p>批量导入时索引会逐行更新，产生巨大性能开销（非主键索引尤为明显）。导入前删除非主键索引，加载完成后重建，可临时调整内存参数加速索引创建。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 1. 查询目标表所有索引，排除主键索引后执行删除</span><span class="token keyword">SELECT</span> indexname <span class="token keyword">FROM</span> pg_indexes <span class="token keyword">WHERE</span> tablename <span class="token operator">=</span> <span class="token string">'&lt;target_table>'</span><span class="token punctuation">;</span><span class="token keyword">DROP</span> <span class="token keyword">INDEX</span> <span class="token operator">&lt;</span>index_name1<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>index_name2<span class="token operator">></span>…<span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 2. 执行批量插入操作，无索引更新开销</span><span class="token operator">&lt;</span>bulk_data_insert_operations<span class="token operator">></span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 3. 临时调整内存参数，重建索引后恢复默认</span><span class="token keyword">SET</span> maintenance_work_mem <span class="token operator">=</span> <span class="token string">'512MB'</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 根据服务器内存调整，建议256MB-1GB</span><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> <span class="token operator">&lt;</span>index_name1<span class="token operator">></span> <span class="token keyword">ON</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span><span class="token punctuation">(</span>column1<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> <span class="token operator">&lt;</span>index_name2<span class="token operator">></span> <span class="token keyword">ON</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span><span class="token punctuation">(</span>column2<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">;</span>RESET maintenance_work_mem<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="3-临时删除外键约束再重建"><a href="#3-临时删除外键约束再重建" class="headerlink" title="3. 临时删除外键约束再重建"></a>3. 临时删除外键约束再重建</h5><p>外键约束会在逐行插入时校验关联数据，海量数据导入时开销急剧累积。临时删除外键约束，单事务完成导入后重建，保证效率与数据一致性。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 1. 删除目标表外键约束（记录约束名，便于后续重建）</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token keyword">DROP</span> <span class="token keyword">CONSTRAINT</span> <span class="token operator">&lt;</span>fk_constraint<span class="token operator">></span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 2. 单事务执行批量插入，减少提交开销并保证一致性</span><span class="token keyword">BEGIN</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span> <span class="token operator">&lt;</span>bulk_data_insert_operations<span class="token operator">></span><span class="token punctuation">;</span> <span class="token keyword">COMMIT</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 3. 重新创建外键约束，校验数据关联性</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token keyword">ADD</span> <span class="token keyword">CONSTRAINT</span> <span class="token operator">&lt;</span>fk_constraint<span class="token operator">></span> <span class="token keyword">FOREIGN</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span>fk_column<span class="token punctuation">)</span> <span class="token keyword">REFERENCES</span> <span class="token operator">&lt;</span>ref_table<span class="token operator">></span><span class="token punctuation">(</span>ref_column<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="4-禁用所有触发器后启用"><a href="#4-禁用所有触发器后启用" class="headerlink" title="4. 禁用所有触发器后启用"></a>4. 禁用所有触发器后启用</h5><p>业务自定义触发器、外键关联的系统触发器，会在逐行插入时执行，产生大量冗余开销。导入前禁用触发器，加载完成后恢复，也可单独禁用非必需触发器。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 1. 禁用目标表所有触发器（替换ALL为具体触发器名可单独禁用）</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token keyword">DISABLE</span> <span class="token keyword">TRIGGER</span> <span class="token keyword">ALL</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 2. 执行批量插入操作，无需触发任何触发器</span><span class="token operator">&lt;</span>bulk_data_insert_operations<span class="token operator">></span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">-- 3. 启用所有触发器，恢复正常业务逻辑</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token keyword">ENABLE</span> <span class="token keyword">TRIGGER</span> <span class="token keyword">ALL</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="5-优先使用-COPY-命令导入"><a href="#5-优先使用-COPY-命令导入" class="headerlink" title="5. 优先使用 COPY 命令导入"></a>5. 优先使用 COPY 命令导入</h5><p>COPY 是 PanWeDB 官方推荐的批量导入命令，专为文件数据源优化，性能远优于普通 INSERT 语句，支持 CSV/TEXT 等格式，适合 GB/TB 级大文件导入。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 基础用法：导入本地文件，指定列、格式及相关参数</span>COPY <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">(</span>column1<span class="token punctuation">,</span> column2<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">FROM</span> <span class="token string">'&lt;file_path>'</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>    FORMAT csv<span class="token punctuation">,</span>      <span class="token comment" spellcheck="true">-- 文件格式，可选csv/text/binary</span>    HEADER <span class="token boolean">true</span><span class="token punctuation">,</span>     <span class="token comment" spellcheck="true">-- 是否包含表头，无表头则设为false</span>    <span class="token keyword">DELIMITER</span> <span class="token string">','</span><span class="token punctuation">,</span>   <span class="token comment" spellcheck="true">-- 字段分隔符，按文件实际情况调整</span>    ENCODING <span class="token string">'UTF8'</span>  <span class="token comment" spellcheck="true">-- 字符编码，避免中文乱码</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>优势</strong>：直接绕开 SQL 解析层，由存储引擎直接读取文件，资源占用低、导入速度快，远程文件（如 S3）开启对应权限后可直接填写远程路径。</p><h5 id="6-采用多值-INSERT-语句"><a href="#6-采用多值-INSERT-语句" class="headerlink" title="6. 采用多值 INSERT 语句"></a>6. 采用多值 INSERT 语句</h5><p>数据源为程序动态生成（无物理文件）时，用多值 INSERT 替代大量单条 INSERT，减少语句解析、网络往返和事务提交开销，单条语句建议控制 500-1000 行。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 多值INSERT：单条语句插入多行数据，逗号分隔每组值</span><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span> <span class="token punctuation">(</span>column1<span class="token punctuation">,</span> column2<span class="token punctuation">,</span> column3<span class="token punctuation">,</span>…<span class="token punctuation">)</span> <span class="token keyword">VALUES</span> <span class="token punctuation">(</span>val1<span class="token punctuation">,</span> val2<span class="token punctuation">,</span> val3<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">(</span>val4<span class="token punctuation">,</span> val5<span class="token punctuation">,</span> val6<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">,</span>       …       <span class="token punctuation">(</span>valN<span class="token number">-2</span><span class="token punctuation">,</span> valN<span class="token number">-1</span><span class="token punctuation">,</span> valN<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>优化补充</strong>：结合 JDBC 批处理时，开启 <code>reWriteBatchedInserts=true</code> 连接参数，驱动会自动将批处理重写为多值 INSERT，进一步提升效率。</p><h5 id="7-导入后执行-ANALYZE-更新统计"><a href="#7-导入后执行-ANALYZE-更新统计" class="headerlink" title="7. 导入后执行 ANALYZE 更新统计"></a>7. 导入后执行 ANALYZE 更新统计</h5><p>批量插入会导致表的统计信息过时，PanWeDB 查询优化器依赖统计信息生成最优执行计划，导入完成后需立即更新统计信息。</p><pre class="line-numbers language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 方式1：更新单个目标表统计信息（推荐，高效快速）</span><span class="token keyword">ANALYZE</span> <span class="token operator">&lt;</span>target_table<span class="token operator">></span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 方式2：同时更新多个表统计信息（适合多表批量导入场景）</span><span class="token keyword">ANALYZE</span> <span class="token operator">&lt;</span>target_table1<span class="token operator">></span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>target_table2<span class="token operator">></span>…<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>执行时机</strong>：建议在所有批量插入操作完成、索引和约束重建后执行。</p><h5 id="8-核心注意事项与补充说明"><a href="#8-核心注意事项与补充说明" class="headerlink" title="8. 核心注意事项与补充说明"></a>8. 核心注意事项与补充说明</h5><p>上述最佳实践可根据实际场景组合使用（如 UNLOGGED 表 + 删除索引 + COPY 命令，为经典高效组合），同时需严格遵循以下注意事项，避免数据丢失、业务异常：</p><ul><li><p>结构修改类操作前置要求：执行删除索引、外键，禁用触发器，切换 UNLOGGED 模式前，必须对目标表及原有结构做全量备份（建议使用 pg_dump 工具），防止数据丢失或结构损坏；所有表结构修改操作完成后，需及时恢复原有配置，避免影响正常业务。</p></li><li><p>内存配置优化：重建索引、外键时，可临时提高 maintenance_work_mem 参数；多值 INSERT、JDBC 批处理执行时，建议合理设置 effective_cache_size（总 RAM 的 50%）、shared_buffers（总 RAM 的 25%），提升执行效率，操作后恢复默认值。</p></li><li><p>集群与数据完整性要求：主备集群环境下，使用 UNLOGGED 模式后，需重新创建主备复制关系，恢复集群同步；重新创建外键约束后，需校验外键关联性，确保数据完整性；所有批量导入操作完成后，需做全量数据校验（行计数、主键唯一性、非空约束等）。</p></li><li><p>方案选择与测试原则：无通用最优方案，需根据实际场景（数据量、表结构、集群架构）组合使用多种优化技巧；所有优化方案需先在与生产环境规格、配置一致的测试/预发环境验证，测试性能与兼容性后，再应用于生产环境；制定完善的回滚预案，若批量导入过程中出现异常，可快速恢复数据库原有状态。</p></li><li><p>后续性能保障：批量导入后除执行 ANALYZE 外，若表数据量变化极大（超过 50%），可根据实际情况做索引碎片整理（如 REINDEX 命令），提升后续查询性能；记录本次批量导入的优化方案、执行耗时、资源占用等信息，为后续同类操作积累经验。</p></li></ul><h3 id="4-4-2-日志批量落盘最佳实践-checkpoint"><a href="#4-4-2-日志批量落盘最佳实践-checkpoint" class="headerlink" title="4.4.2 日志批量落盘最佳实践(checkpoint)"></a>4.4.2 日志批量落盘最佳实践(checkpoint)</h3><p><strong>checkpoint机制介绍</strong><br><strong>最佳实践介绍</strong><br><strong>注意事项</strong></p><p>4.5拆分术（恩墨）</p><p>4.6扩展术（恩墨）</p><p>4.7连接收敛术（恩墨）</p><p>4.8削峰填谷术（恩墨）</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 缓存，索引,分区 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第六章--监控命令</title>
      <link href="/2026/6.jian-kong-ming-ling/"/>
      <url>/2026/6.jian-kong-ming-ling/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><p>本章介绍Linux环境下系统资源监控的核心命令，重点讲解sar、uptime、mpstat、iostat、ipcs五大高频命令的应用。这些命令分别针对CPU、磁盘I/O、共享内存等关键系统资源，实现快速巡检、性能统计与瓶颈定位，覆盖日常运维及故障排查核心场景，可直接应用于生产环境，助力保障服务器稳定高效运行。</p><span id="more"></span><h2 id="6-1-sar-命令"><a href="#6-1-sar-命令" class="headerlink" title="6.1 sar 命令"></a>6.1 sar 命令</h2><h3 id="6-1-1-sar-工具简介"><a href="#6-1-1-sar-工具简介" class="headerlink" title="6.1.1 sar 工具简介"></a>6.1.1 sar 工具简介</h3><p>System Activity Reporter（sar）是一款功能强大的系统性能分析工具，隶属于 Sysstat 系统资源工具包，是Linux系统管理员必备的系统监控工具之一。它能够全面采集并分析系统各类性能数据，包括 CPU 活动、内存与分页、中断、设备负载、网络状态、进程线程分配及交换空间使用等，所有数据均来源于 /proc 文件系统。</p><p>默认情况下，sar 每小时的固定节点会自动采集一次系统数据，用于后续的历史性能分析与问题排查。本教程将详细讲解 sar 工具在 Linux 系统中的安装、配置方法，并结合常用命令示例，帮助你快速上手使用 sar 监控Linux系统。</p><h3 id="6-1-2-sar-常用命令速查表"><a href="#6-1-2-sar-常用命令速查表" class="headerlink" title="6.1.2 sar 常用命令速查表"></a>6.1.2 sar 常用命令速查表</h3><table><thead><tr><th align="center">监控对象</th><th align="center">sar 命令</th><th align="center">补充说明</th></tr></thead><tbody><tr><td align="center">监控网卡</td><td align="center">sar -n DEV</td><td align="center">查看网卡收发数据包、流量等详细信息</td></tr><tr><td align="center">监控 TCP</td><td align="center">sar -n TCP</td><td align="center">监控 TCP 连接状态、收发数据等指标</td></tr><tr><td align="center">监控 UDP</td><td align="center">sar -n UDP</td><td align="center">查看 UDP 数据包收发情况</td></tr><tr><td align="center">监控 SOCK</td><td align="center">sar -n SOCK</td><td align="center">监控系统 socket 连接总数及状态</td></tr><tr><td align="center">监控 CPU</td><td align="center">sar -u</td><td align="center">查看整体 CPU 使用率（用户态、系统态等）</td></tr><tr><td align="center">监控队列</td><td align="center">sar -q</td><td align="center">监控进程队列长度、系统平均负载等</td></tr><tr><td align="center">监控上下文切换</td><td align="center">sar -w</td><td align="center">查看系统上下文切换频率，反映 CPU 调度情况</td></tr><tr><td align="center">监控内存（分页相关）</td><td align="center">sar -B</td><td align="center">监控内存分页交换情况（页面换入 / 换出速率）</td></tr><tr><td align="center">监控内存（使用情况）</td><td align="center">sar -r</td><td align="center">查看内存空闲、已用、缓存等详细使用状态</td></tr><tr><td align="center">监控 SWAP（交换空间）</td><td align="center">sar -W</td><td align="center">监控交换空间的使用情况及交换速率</td></tr><tr><td align="center">监控磁盘（I/O 吞吐量）</td><td align="center">sar -b</td><td align="center">查看磁盘 I/O 总吞吐量、读写速率等</td></tr><tr><td align="center">监控磁盘（设备负载）</td><td align="center">sar -d</td><td align="center">查看单个磁盘设备的 I/O 负载、响应时间等</td></tr></tbody></table><h3 id="6-1-3-sar-安装与配置"><a href="#6-1-3-sar-安装与配置" class="headerlink" title="6.1.3 sar 安装与配置"></a>6.1.3 sar 安装与配置</h3><p>sar 工具并不默认包含在 Linux 系统中，需通过安装 sysstat 软件包获取。本教程以 <strong>BCLinux 21.10</strong> 系统为例，讲解具体安装与配置步骤。</p><p><strong>安装 sar</strong></p><p>BCLinux 21.10 系统默认使用 dnf 作为包管理器，打开终端，执行以下命令安装 sysstat，安装完成后即可直接使用 sar 命令：</p><pre class="line-numbers language-bash"><code class="language-bash">dnf <span class="token function">install</span> sysstat -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>启用 sar 数据采集</strong></p><p>安装完成后，需先启用 sar 的数据采集功能，否则无法自动收集系统历史性能数据。步骤如下：</p><ol><li>打开 sar 的核心配置文件：</li></ol><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/sysconfig/sysstat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>找到<code>ENABLED</code>项，修改为：<code>ENABLED="true"</code>（注释则先取消），保存退出。</p><pre class="line-numbers language-bash"><code class="language-bash">ENABLED<span class="token operator">=</span><span class="token string">"true"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>启动 sysstat 相关服务并设置开机自启：</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 启动采集+汇总定时器，直接生效</span>systemctl <span class="token function">enable</span> --now sysstat-collect.timer sysstat-summary.timer<span class="token comment" spellcheck="true"># 主服务开机自启</span>systemctl <span class="token function">enable</span> sysstat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>验证采集功能是否正常运行：</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 查看定时器状态</span>systemctl list-timers <span class="token operator">|</span> <span class="token function">grep</span> sysstat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>核心配置修改</strong></p><p>若需自定义采集频率、日志保留时间等，可修改对应文件。</p><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/sysconfig/sysstat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 保留30天历史日志（默认7天，按需改）</span>HISTORY<span class="token operator">=</span>30<span class="token comment" spellcheck="true"># 超过10天的日志自动压缩</span>COMPRESSAFTER<span class="token operator">=</span>10<span class="token comment" spellcheck="true"># 日志保存目录（系统默认，无需改）</span>SA_DIR<span class="token operator">=</span>/var/log/sa<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如需采集全量性能指标</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 采集CPU/内存/磁盘/网络等所有指标（默认仅磁盘）</span>SADC_OPTIONS<span class="token operator">=</span><span class="token string">"-S XALL"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>配置修改后<strong>无需重启服务</strong>，下次采集自动生效。</p><p><strong>自定义采集频率</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建配置覆盖目录（自动生效，不修改系统默认文件）</span><span class="token function">mkdir</span> -p /etc/systemd/system/sysstat-collect.timer.d/<span class="token comment" spellcheck="true"># 写入自定义频率配置</span><span class="token function">cat</span> <span class="token operator">></span> /etc/systemd/system/sysstat-collect.timer.d/override.conf <span class="token operator">&lt;&lt;</span> <span class="token string">'EOF'[Timer]OnCalendar=*:0/5  # 每5分钟采集一次，改*:*则每分钟EOF</span><span class="token comment" spellcheck="true"># 重载配置并重启定时器</span>systemctl daemon-reload <span class="token operator">&amp;&amp;</span> systemctl restart sysstat-collect.timer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>验证数据采集</strong></p><p>配置完成后需等待<strong>第一个采集周期</strong>（如 5/10 分钟），再验证：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看是否生成数据文件（saXX为当月日期，如sa28）</span><span class="token function">ls</span> -l /var/log/sa/<span class="token comment" spellcheck="true"># 2. 查看今日采集的性能数据（直接运行，自动读取当日文件）</span>sar<span class="token comment" spellcheck="true"># 3. 手动触发一次采集（测试用，立即生成数据）</span>/usr/lib64/sa/sa1 1 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-1-5-sar-命令基础使用方法"><a href="#6-1-5-sar-命令基础使用方法" class="headerlink" title="6.1.5 sar 命令基础使用方法"></a>6.1.5 sar 命令基础使用方法</h3><p>sar 命令的使用分为<strong>实时监控</strong>（查看当前系统性能）和<strong>历史查询</strong>（查看已采集的历史数据）两种核心场景，在 BCLinux 系统中的用法与原生 Linux 一致，核心语法如下：</p><p><strong>核心语法</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 实时监控：无-f选项，直接指定监控参数+采样间隔+采样次数</span>sar <span class="token punctuation">[</span>选项<span class="token punctuation">]</span> <span class="token punctuation">[</span>采样间隔<span class="token punctuation">]</span> <span class="token punctuation">[</span>采样次数<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 2. 历史查询：使用-f选项指定默认的历史数据文件路径</span>sar <span class="token punctuation">[</span>选项<span class="token punctuation">]</span> -f /var/log/sysstat/saXX<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>参数说明</strong></p><ul><li>采样间隔：每次采集数据的时间间隔（单位：秒）。</li><li>采样次数：需要采集的次数；若不指定，默认采集一次（实时监控）或显示该文件的所有历史数据（历史查询）。</li><li>saXX：历史数据文件名，XX 对应当月日期（如 15 表示当月 15 号的历史数据），文件位于默认的<code>/var/log/sysstat/</code>目录。</li></ul><p><strong>基础示例（查看历史 CPU 数据）</strong></p><p>执行以下命令，查看当月 24 号的 CPU 累计使用情况（需替换 sa24 为你系统中存在的文件名）：</p><pre class="line-numbers language-bash"><code class="language-bash">sar -u -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>典型输出</strong></p><pre class="line-numbers language-bash"><code class="language-bash">Linux 4.19.90-2107.6.0.0100.oe1.bclinux.x86_64 <span class="token punctuation">(</span>hostname<span class="token punctuation">)</span>     01/28/2026      _x86_64_        <span class="token punctuation">(</span>4 CPU<span class="token punctuation">)</span>09:00:01 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle09:10:01 AM     all      0.25      0.00      0.12      0.03      0.00     99.6009:20:01 AM     all      0.23      0.00      0.11      0.02      0.00     99.64Average:        all      0.24      0.00      0.11      0.02      0.00     99.62<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>输出字段说明</strong></p><ul><li><code>Linux 4.19.90-2107.6.0.0100.oe1.bclinux.x86_64</code>：bclinux系统的内核版本。</li><li><code>hostname</code>：采集数据的主机名。</li><li><code>01/28/2026</code>：数据采集日期。</li><li><code>x86_64</code>：系统架构。</li><li><code>(4 CPU)</code>：系统可用 CPU 核心数。</li><li><code>%user</code>：CPU 在用户态的使用率（运行用户应用程序的时间占比）。</li><li><code>%nice</code>：CPU 在 nice 优先级进程上的使用率（调整过优先级的用户进程）。</li><li><code>%system</code>：CPU 在内核态的使用率（运行系统内核指令的时间占比）。</li><li><code>%iowait</code>：CPU 等待 I/O 操作完成的时间占比（I/O 瓶颈会导致该值升高）。</li><li><code>%steal</code>：被虚拟化环境中其他虚拟机占用的 CPU 时间占比。</li><li><code>%idle</code>：CPU 空闲时间占比（该值过低表示 CPU 负载过高）。</li></ul><h3 id="6-1-6-sar-常用命令详细示例"><a href="#6-1-6-sar-常用命令详细示例" class="headerlink" title="6.1.6 sar 常用命令详细示例"></a>6.1.6 sar 常用命令详细示例</h3><p>结合前面的速查表，以下是 <strong>BCLinux</strong> 系统中各监控场景的详细使用示例，包含实时监控、历史查询及输出说明，以帮助快速排查系统性能问题。</p><p><strong>CPU 监控（sar -u /sar -P）</strong></p><p><strong>查看整体 CPU 使用率</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看当前日期已采集的CPU使用率（默认显示所有历史采样点）</span>sar -u<span class="token comment" spellcheck="true"># 2. 实时监控：每1秒采集一次，共采集3次，快速查看当前CPU负载</span>sar -u 1 3<span class="token comment" spellcheck="true"># 3. 历史查询：查看当月28号的CPU使用率</span>sar -u -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>查看单个 / 所有 CPU 核心使用率</strong></p><p>当系统存在多个 CPU 核心时，可通过<code>-P</code>选项查看单个 / 所有核心的负载情况，精准定位 CPU 瓶颈：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看所有CPU核心的使用率（当前日期历史数据）</span>sar -P ALL<span class="token comment" spellcheck="true"># 2. 实时监控：每1秒采集一次，共3次，查看所有核心负载</span>sar -P ALL 1 3<span class="token comment" spellcheck="true"># 3. 查看单个核心（如核心1，核心编号从0开始）的使用率</span>sar -P 1<span class="token comment" spellcheck="true"># 4. 历史查询：查看当月28号所有核心的使用率</span>sar -P ALL -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>内存监控（sar -r /sar -B）</strong></p><p><strong>查看内存使用详情（sar -r）</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看当前日期内存使用情况（空闲、已用、缓存等）</span>sar -r<span class="token comment" spellcheck="true"># 2. 实时监控：每1秒采集一次，共3次</span>sar -r 1 3<span class="token comment" spellcheck="true"># 3. 历史查询：查看当月28号内存使用情况</span>sar -r -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>典型输出字段说明（单位：KB）</strong></p><ul><li>kbmemfree：系统空闲内存大小。</li><li>kbavail：可直接分配给应用程序的内存大小（包含空闲内存 + 可回收缓存），Linux 系统中该指标为内存剩余的核心参考。</li><li>kbmemused：已使用内存大小（包含缓存、缓冲区，非实际应用占用）。</li><li>% memused：内存使用率（需结合 kbavail 判断，避免被缓存占用误导）。</li><li>kbbuffers：用于内核缓冲区的内存大小（存储磁盘 I/O 临时数据）。</li><li>kbcached：用于页面缓存的内存大小（存储文件内容，可随时回收）。</li></ul><p><strong>查看内存分页交换（sar -B）</strong></p><p>用于监控内存分页（页面换入 / 换出）情况，反映 Linux 系统是否内存不足（频繁分页会导致系统卡顿、应用响应缓慢）：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 实时监控：每1秒采集一次，共3次，查看分页交换速率</span>sar -B 1 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>交换空间监控（sar -W）</strong></p><p>交换空间（SWAP）是 Linux 系统硬盘上的一块虚拟内存区域，当物理内存不足时，系统会将部分内存数据写入 SWAP，<strong>频繁使用 SWAP 会严重降低系统性能</strong>，需重点监控：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看当前日期SWAP使用情况</span>sar -W<span class="token comment" spellcheck="true"># 2. 实时监控：每1秒采集一次，共3次</span>sar -W 1 3<span class="token comment" spellcheck="true"># 3. 历史查询：查看当月28号SWAP使用情况</span>sar -W -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>输出字段说明</strong></p><ul><li>pswpin/s  # 每秒从交换空间换入物理内存的页面数（pages/秒） </li><li>pswpout/s # 每秒从物理内存换出到交换空间的页面数（pages/秒）</li></ul><p><strong>磁盘 I/O 监控（sar -b /sar -d）</strong></p><p>Linux 系统常用于服务器场景，磁盘 I/O 是性能瓶颈的高频点，通过 sar 可精准监控磁盘吞吐量和单设备负载。</p><p><strong>查看磁盘整体 I/O 吞吐量（sar -b）</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 查看当前日期磁盘I/O整体情况</span>sar -b<span class="token comment" spellcheck="true"># 2. 实时监控：每1秒采集一次，共3次</span>sar -b 1 3<span class="token comment" spellcheck="true"># 3. 历史查询：查看当月24号磁盘I/O吞吐量</span>sar -b -f /var/log/sa/sa28<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>常用输出字段说明</strong></p><ul><li>tps：每秒磁盘 I/O 请求总数（包含读请求和写请求）。</li><li>rtps：每秒磁盘读请求数。</li><li>wtps：每秒磁盘写请求数。</li><li>bread/s：每秒从磁盘读取的数据量（单位：块 / 秒）。</li><li>bwrtn/s：每秒向磁盘写入的数据量（单位：块 / 秒）。</li></ul><p><strong>查看单个磁盘设备负载（sar -d）</strong></p><p>定位 Linux系统中<strong>具体哪个磁盘设备</strong>存在 I/O 瓶颈（如系统盘、数据盘），精准定位存储问题：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 实时监控：每1秒采集一次，共3次，查看所有磁盘设备的I/O负载</span>sar -d 1 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>网络监控（sar -n）</strong></p><p>sar -n 支持多种网络监控类型，适配linux系统的服务器网络场景，结合速查表，常用示例如下（可快速排查网络丢包、流量过高问题）：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 监控网卡（DEV）：查看所有网卡收发数据包、流量、丢包率等</span>sar -n DEV 1 3<span class="token comment" spellcheck="true"># 2. 监控TCP连接：查看TCP连接状态（ESTABLISHED、LISTEN等）、收发包数</span>sar -n TCP 1 3<span class="token comment" spellcheck="true"># 3. 监控UDP：查看UDP数据包收发情况、端口使用情况</span>sar -n UDP 1 3<span class="token comment" spellcheck="true"># 4. 监控socket连接：查看系统socket总数及各状态连接数</span>sar -n SOCK 1 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>其他常用监控</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 1. 监控进程队列（sar -q）：查看系统平均负载、进程等待队列长度，反映系统整体繁忙程度</span>sar -q 1 3<span class="token comment" spellcheck="true"># 2. 监控上下文切换（sar -w）：查看CPU上下文切换频率，反映CPU调度压力（频率过高表示进程调度频繁）</span>sar -w 1 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-1-7-sar命令使用建议"><a href="#6-1-7-sar命令使用建议" class="headerlink" title="6.1.7 sar命令使用建议"></a>6.1.7 sar命令使用建议</h3><p>结合 Linux的系统特性和服务器端的使用场景，给出以下针对性使用建议：</p><ol><li><strong>查看官方手册</strong>：sar 命令的选项和字段较多，可通过执行<code>man sar</code>查看完整手册，同时可通过<code>dnf info sysstat</code>查看 BCLinux系统中 sysstat 包的适配说明。</li><li><strong>结合历史数据排查问题</strong>：BCLinux 服务器出现性能瓶颈（如应用卡顿、服务无响应、负载过高）时，通过<code>sar -f</code>查看对应时间段的历史数据，精准定位问题根源（CPU 负载过高、磁盘 I/O 瓶颈、内存不足、网络流量异常等）。</li><li><strong>适配服务器采集频率</strong>：对于高负载的 BCLinux 生产服务器，可将采集频率调整为 1 分钟一次（修改<code>/etc/cron.d/sysstat</code>中的<code>*/10</code>为<code>*/1</code>），便于更精准地捕捉性能波动；对于低负载服务器，保持默认 10 分钟采集即可，减少系统资源消耗。</li><li><strong>开启全量采集数据</strong>：若 BCLinux  系统用于核心业务监控，将<code>/etc/sysstat/sysstat</code>中的<code>SADC_OPTIONS</code>改为<code>SADC_OPTIONS="-S XALL"</code>，采集 CPU、内存、磁盘、网络、进程、中断等全量指标，为问题排查提供完整数据支撑。</li><li><strong>日志目录权限</strong>：BCLinux 系统中<code>/var/log/sysstat/</code>目录默认归 root 用户所有，普通用户查看历史数据需加<code>sudo</code>，若需开放权限，可通过<code>chmod</code>调整目录权限（不建议生产环境操作）。</li></ol><h2 id="6-2-uptime监控CPU负载"><a href="#6-2-uptime监控CPU负载" class="headerlink" title="6.2 uptime监控CPU负载"></a>6.2 uptime监控CPU负载</h2><p>在系统性能监控中，了解CPU的负载情况至关重要。<code>uptime</code> 命令是一个简洁有效的工具，可以帮助我们获取系统的负载平均值。通过分析这些负载值，我们可以判断系统在不同时间段内的工作状态，从而做出相应的调整和优化。</p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a><strong>环境准备</strong></h3><p>本教程适用于各种 Unix/Linux 系统，确保您有权限访问终端并运行命令。</p><hr><h3 id="CPU-负载监控"><a href="#CPU-负载监控" class="headerlink" title="CPU 负载监控"></a><strong>CPU 负载监控</strong></h3><h4 id="使用-uptime-监控-CPU-负载"><a href="#使用-uptime-监控-CPU-负载" class="headerlink" title="使用 uptime 监控 CPU 负载"></a><strong>使用 uptime 监控 CPU 负载</strong></h4><p><strong>操作步骤：</strong></p><ol><li><p><strong>打开终端</strong>：在您的服务器或工作站上打开一个终端窗口。</p></li><li><p><strong>执行 uptime 命令</strong>：</p><p>在终端中输入以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash">bashuptime<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>您将看到类似于以下的输出：</p><pre class="line-numbers language-bash"><code class="language-bash">14:29:38 up  3:16,  1 user,  load average: 20.29, 19.10, 18.50<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h3 id="输出指标解读"><a href="#输出指标解读" class="headerlink" title="输出指标解读"></a><strong>输出指标解读</strong></h3><p>在上面的输出中，重点关注最后三个数字，它们代表了系统负载在过去1分钟、5分钟和15分钟内的平均值。这些值分别为：</p><ul><li><strong>1分钟平均负载</strong>：20.29</li><li><strong>5分钟平均负载</strong>：19.10</li><li><strong>15分钟平均负载</strong>：18.50</li></ul><p><strong>负载平均值的含义</strong></p><ul><li><strong>负载的概念</strong>：负载平均值并不是简单的数学均值，而是基于指数衰减的累加值。它表示在特定时间段内，系统中处于可运行状态和不可中断等待状态的任务数量。</li><li><strong>任务状态</strong>：<ul><li><strong>可运行状态</strong>：指的是正在等待CPU资源的任务。</li><li><strong>不可中断等待状态</strong>：指的是因I/O操作或锁等待而无法继续执行的任务。</li></ul></li></ul><h3 id="负载趋势分析"><a href="#负载趋势分析" class="headerlink" title="负载趋势分析"></a><strong>负载趋势分析</strong></h3><p>通过比较这三个时间段的平均负载值，可以分析系统负载的变化趋势。例如，在上述例子中，1分钟平均负载值（20.29）高于15分钟平均负载值（18.50），这表明系统的负载在最近1分钟内有所上升。</p><p><strong>判断系统负载是否饱和</strong></p><p>为了评估负载是否过高，可以将平均负载值与CPU核心数进行比较。假设您的系统有16个CPU核心，您可以做如下计算：</p><ul><li><strong>负载比</strong> = 1分钟平均负载 / CPU核心数</li><li><strong>判断</strong>：如果负载比超过1.0，说明系统中的CPU资源可能处于饱和状态。</li></ul><p>在本例中：</p><pre class="line-numbers language-bash"><code class="language-bash">负载比 <span class="token operator">=</span> 20.29 / 16 ≈ 1.27<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这意味着在过去的一分钟内，系统中可用的CPU资源已经不足，任务的排列可能导致响应时间变慢。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>通过 <code>uptime</code> 命令监控CPU负载，可以帮助您快速评估系统的性能状态。尽管负载平均值提供了一些关于系统负载需求的见解，但请记住，这些值通常仅用于负载趋势分析，而不能直接作为CPU利用率的衡量标准。为了获得更全面的性能分析，建议结合其他工具（如 <code>mpstat</code>、<code>top</code> 等）进行综合评估。</p><h2 id="6-3-mpstat辨认CPU瓶颈"><a href="#6-3-mpstat辨认CPU瓶颈" class="headerlink" title="6.3 mpstat辨认CPU瓶颈"></a>6.3 mpstat辨认CPU瓶颈</h2><p>利用 <code>mpstat</code> 工具，我们可以深入了解系统中每个CPU的使用情况，从而帮助我们识别潜在的性能瓶颈和负载不均衡的问题。以下是如何使用 <code>mpstat</code> 来监控和分析CPU使用率的详细步骤。</p><h3 id="环境准备-1"><a href="#环境准备-1" class="headerlink" title="环境准备"></a><strong>环境准备</strong></h3><p>本教程基于 <strong>BCLinux21.10</strong> 系统，但其他 Unix/Linux 发行版的命令输出可能略有差异。尽管如此，核心原理和指标解读方式基本一致。</p><hr><h3 id="CPU监控"><a href="#CPU监控" class="headerlink" title="CPU监控"></a><strong>CPU监控</strong></h3><h4 id="使用-mpstat-监控-CPU-使用率"><a href="#使用-mpstat-监控-CPU-使用率" class="headerlink" title="使用 mpstat 监控 CPU 使用率"></a><strong>使用 mpstat 监控 CPU 使用率</strong></h4><p><strong>操作步骤：</strong></p><ol><li><p><strong>安装 sysstat 包（如未安装）</strong></p><p>在终端中执行以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash">bashyum <span class="token function">install</span> sysstat -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p><strong>执行监控命令：</strong></p><p>使用 <code>mpstat</code> 命令来监控CPU的使用情况：</p><pre class="line-numbers language-bash"><code class="language-bash">bashmpstat -P ALL 1 5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这条命令将每秒输出一次CPU的使用情况，连续输出5次。</p></li></ol><h3 id="示例输出解析"><a href="#示例输出解析" class="headerlink" title="示例输出解析"></a><strong>示例输出解析</strong></h3><p>运行命令后，您将看到类似以下的输出：</p><pre class="line-numbers language-bash"><code class="language-bash">plaintextLinux 4.19.90-2107.6.0.0100.oe1.bclinux.x86_64 <span class="token punctuation">(</span>panweidb91<span class="token punctuation">)</span>     01/28/2026      _x86_64_        <span class="token punctuation">(</span>4 CPU<span class="token punctuation">)</span>02:05:33 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle02:05:34 PM  all    0.00    0.00    0.00    0.00    0.25    0.00    0.00    0.00    0.00   99.7502:05:34 PM    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.0002:05:34 PM    1    0.00    0.00    0.00    0.00    0.97    0.00    0.00    0.00    0.00   99.0302:05:34 PM    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.0002:05:34 PM    3    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>输出指标解读：</strong></p><ul><li><strong>%usr</strong>：表示用户空间进程占用CPU的比例。高值可能意味着应用程序负载较重。</li><li><strong>%sys</strong>：表示内核空间占用CPU的比例。高值通常表明系统调用频繁，或者驱动程序存在问题。</li><li><strong>%iowait</strong>：表示CPU等待I/O操作完成的时间比例。若该值持续较高，可能意味着存储设备的I/O性能不足。</li><li><strong>%idle</strong>：表示CPU空闲的时间比例。若该值低于20%，则可能表示CPU资源紧张，需要考虑优化进程或增加硬件资源。</li></ul><h3 id="常见性能问题判断"><a href="#常见性能问题判断" class="headerlink" title="常见性能问题判断"></a><strong>常见性能问题判断</strong></h3><p>通过分析这些指标，我们可以判断系统的性能状态，例如：</p><ul><li><strong>高 %iowait</strong>：如果 <code>%iowait</code> 持续处于高位，表明可能存在存储I/O瓶颈，需检查磁盘性能。</li><li><strong>低 %idle</strong>：当 <code>%idle</code> 长期低于20%，说明CPU资源紧张，可能需要优化现有进程，或考虑扩容。</li></ul><h3 id="负载均衡问题识别"><a href="#负载均衡问题识别" class="headerlink" title="负载均衡问题识别"></a><strong>负载均衡问题识别</strong></h3><p><code>mpstat</code> 工具每秒钟输出每个CPU的使用数据，可以帮助识别负载不均衡的问题。例如，如果某些CPU的使用率很高，而其他CPU的使用率却很低，可能暗示着以下几种情况：</p><ul><li><strong>应用程序配置不合理</strong>：如应用的线程池、工作进程数配置过小，无法充分调度和利用服务器的所有 CPU 核心，导致业务请求集中在少数核心上处理；</li><li><strong>资源绑定限制</strong>：人为或软件层面将特定进程、容器、服务绑定到部分 CPU 核心上运行，限制了 CPU 资源的调度范围，造成绑定核心负载过高，其余核心闲置；</li><li><strong>软件层面缺陷</strong>：应用程序本身存在代码 bug、逻辑缺陷，或依赖的中间件、底层库存在调度问题，导致业务处理逻辑无法均匀分配到多个 CPU 核心，引发负载倾斜；</li><li><strong>系统调度策略适配问题</strong>：极少数情况下，系统内核的 CPU 调度策略与业务场景不匹配，也会导致核心间负载分配不均。</li></ul><p>若服务器存在上述 CPU 负载均衡问题，即便整体 CPU 使用率未达到阈值，也会因部分核心被占满，导致业务请求处理缓慢、响应延迟增加，最终表现为系统性能瓶颈，因此通过<code>mpstat</code>识别负载均衡问题，是定位 CPU 瓶颈的重要环节。</p><h2 id="6-4-iostat监控磁盘I-x2F-O"><a href="#6-4-iostat监控磁盘I-x2F-O" class="headerlink" title="6.4 iostat监控磁盘I/O"></a>6.4 iostat监控磁盘I/O</h2><p><code>iostat</code> 是 Unix/Linux 系统中一款强大的磁盘 I/O 性能监控工具，通过它可实时获取各磁盘的 I/O 操作统计信息，包括 IOPS（每秒输入输出操作数）、吞吐量、I/O 请求时长及磁盘使用率等关键指标，助力快速定位磁盘性能瓶颈。以下是详细的使用教程，适用于各类 Unix/Linux 系统用户。</p><h3 id="环境准备-2"><a href="#环境准备-2" class="headerlink" title="环境准备"></a>环境准备</h3><p>本教程适配所有 Unix/Linux 发行版（如 CentOS、Ubuntu、Debian 等），只需满足两个条件：</p><ul><li>拥有系统终端访问权限（可通过 SSH 远程连接服务器或直接操作本地工作站）；</li><li>系统已预装 <code>iostat</code>（默认集成在 sysstat 工具包中，若未安装，可通过 <code>yum install sysstat</code> 或 <code>apt install sysstat</code> 命令快速安装）。</li></ul><h3 id="iostat-核心使用方法"><a href="#iostat-核心使用方法" class="headerlink" title="iostat 核心使用方法"></a>iostat 核心使用方法</h3><p><strong>基本命令（常用推荐）</strong></p><p>监控磁盘 I/O 最常用的命令的是带详细参数的实时输出模式，步骤如下：</p><ol><li>打开终端：本地操作直接打开终端窗口，远程服务器通过 SSH 工具（如 Xshell、Putty）连接后进入终端；</li><li>执行核心命令：输入以下命令，启动实时监控并输出详细信息：        <code>iostat -dxz 1</code></li></ol><p>命令参数详细解读（重点必看）：</p><ul><li>-d：仅显示磁盘相关的 I/O 统计信息，屏蔽 CPU 相关统计（聚焦磁盘，避免信息干扰）；</li><li>-x：显示扩展的详细统计列，包含请求时长、队列长度等关键性能指标（默认仅显示基础指标）；</li><li>-z：忽略所有指标为 0 的磁盘设备，仅显示有 I/O 活动的设备（精简输出，提升可读性）；</li><li>1：指定统计信息的输出间隔，单位为秒（此处表示每秒刷新一次，可根据需求修改，如 5 表示每 5 秒刷新）。</li></ul><p>补充说明：若需停止监控，按下键盘 <code>Ctrl + C</code> 即可终止命令运行。</p><p><strong>输出结果解读</strong></p><p>执行上述命令后，终端会持续输出类似以下的统计结果（以两块磁盘 xvda、xvdb 为例）：</p><pre class="line-numbers language-bash"><code class="language-bash">Device          r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz  w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz  d/s     dkB/s   drqm/s  %drqm d_await dareq-sz  f/s   f_await  aqu-sz  %utilxvda           150.00   12000.00   5.00    3.33   15.00   80.00   200.00  15000.00  10.00   5.00   20.00  75.00   0.50   20.00   2.00    1.00   25.00   1.50    0.20   100.00   15.00   85.00xvdb           90.00    8000.00    2.00    2.22   30.00   90.00   50.00   4000.00   3.00    6.00   10.00  80.00   1.00   15.00   0.50    0.50   12.00   0.80    0.10   90.00    8.00   70.00<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>关键列含义</strong></p><p>输出列较多，以下是日常性能监控中最常用、最关键的列解读，其余列可根据实际需求参考：</p><ul><li><strong>Device</strong>：磁盘设备名称（如 xvda、xvdb，对应系统中的物理磁盘或虚拟磁盘）；</li><li><strong>r/s</strong>：每秒完成的读请求数（读 IOPS，反映磁盘读操作的频繁程度）；</li><li><strong>rkB/s</strong>：每秒从磁盘读取的数据量（读吞吐量，单位：千字节，直观反映读速度）；</li><li><strong>w/s</strong>：每秒完成的写请求数（写 IOPS，反映磁盘写操作的频繁程度）；</li><li><strong>wkB/s</strong>：每秒向磁盘写入的数据量（写吞吐量，单位：千字节，直观反映写速度）；</li><li><strong>r_await</strong>：平均读请求等待时长（单位：毫秒，包含队列等待时间+磁盘处理时间，数值越小越好）；</li><li><strong>w_await</strong>：平均写请求等待时长（单位：毫秒，解读同 r_await）；</li><li><strong>aqu-sz</strong>：I/O 请求等待队列的平均长度（队列越长，说明磁盘处理能力不足，容易出现阻塞）；</li><li><strong>%util</strong>：磁盘忙于处理 I/O 请求的时间百分比（核心指标，反映磁盘负载情况）。</li></ul><p>补充：d/、f/ 开头的列（如 d/s、f/s）对应设备级、文件系统级的额外统计，日常监控中若无需精细化分析，可暂时忽略。</p><p><strong>性能分析技巧</strong></p><p>通过解读输出指标，可快速判断磁盘 I/O 性能状态，定位瓶颈，以下是最实用的分析方法：</p><ol><li><strong>判断磁盘负载是否过高</strong>：核心看 %util 指标。        <ol><li>若 %util 长期在 80%~100% 之间，说明磁盘处于高负载状态，可能导致 I/O 阻塞；</li><li>若 %util 接近 100%，且 r_await、w_await 数值较大（如超过 20ms），则可确定磁盘 I/O 是系统性能瓶颈。</li></ol></li><li><strong>区分瓶颈类型（读/写瓶颈）</strong>：结合 r/s、w/s、rkB/s、wkB/s 判断。        <ol><li>若 r/s、rkB/s 数值较大，且 r_await 偏高，说明存在读瓶颈（如频繁读取大文件、数据库全表扫描）；</li><li>若 w/s、wkB/s 数值较大，且 w_await 偏高，说明存在写瓶颈（如频繁写入大量小文件、日志刷盘过于频繁）。</li></ol></li><li><strong>排查队列阻塞问题</strong>：看 aqu-sz 指标。若 aqu-sz 长期大于 2，说明 I/O 请求队列过长，磁盘处理速度跟不上请求产生速度，需优化磁盘或业务逻辑。</li><li><strong>定位异常磁盘</strong>：对比多块磁盘的指标，若某一块磁盘的 %util、await 远高于其他磁盘，说明该磁盘存在异常（如磁盘损坏、分区不合理）。</li></ol><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><code>iostat</code> 命令的核心价值的是“简单、高效、精准”，无需复杂配置，通过简单参数即可实时监控磁盘 I/O 状态。日常使用中，记住以下核心要点即可满足大部分监控需求：</p><ul><li>常用命令：<code>iostat -dxz 1</code>（实时、详细、精简输出）；</li><li>核心指标：%util（负载）、r_await/w_await（请求时长）、aqu-sz（队列长度）；</li><li>核心用途：快速定位磁盘 I/O 瓶颈，为系统优化、容量规划、资源调整提供数据支撑。</li></ul><h2 id="6-5-ipcs确认共享内存"><a href="#6-5-ipcs确认共享内存" class="headerlink" title="6.5 ipcs确认共享内存"></a>6.5 ipcs确认共享内存</h2><p>下面是关于如何使用 <code>ipcs</code> 命令查看磐维数据库（Panweidb）使用的共享内存的简单教程。</p><h3 id="6-5-1-使用-ipcs-命令"><a href="#6-5-1-使用-ipcs-命令" class="headerlink" title="6.5.1 使用 ipcs 命令"></a>6.5.1 使用 <code>ipcs</code> 命令</h3><p><code>ipcs</code> 命令用于显示系统中的消息队列、共享内存段和信号量的信息。您可以使用不同的选项来定制输出。</p><h4 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a><strong>基本命令</strong></h4><pre class="line-numbers language-bash"><code class="language-bash">ipcs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此命令将显示所有 IPC 资源的信息，包括消息队列、共享内存和信号量。</p><h3 id="6-5-2-查看共享内存段"><a href="#6-5-2-查看共享内存段" class="headerlink" title="6.5.2 查看共享内存段"></a><strong>6.5.2 查看共享内存段</strong></h3><p>要查看具体的共享内存段，您可以使用以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash">ipcs -m<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该命令将输出当前系统的所有共享内存段信息，包括每个段的键（key）、标识符（shmid）、拥有者（owner）、权限（perms）、字节数（bytes）、附加次数（nattch）和状态（status）。</p><h4 id="示例输出分析"><a href="#示例输出分析" class="headerlink" title="示例输出分析"></a><strong>示例输出分析</strong></h4><p>输出示例：</p><pre class="line-numbers language-bash"><code class="language-bash">plaintext------ Shared Memory Segments --------key        shmid      owner      perms      bytes      nattch     status0x010e14a1 0          omm        600        815420360  1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li><strong>key</strong>：共享内存段的唯一标识符。</li><li><strong>shmid</strong>：共享内存段的 ID。</li><li><strong>owner</strong>：创建该共享内存段的用户。</li><li><strong>perms</strong>：访问权限（600 表示可读可写）。</li><li><strong>bytes</strong>：共享内存段的大小（815420360 字节）。</li><li><strong>nattch</strong>：当前附加到该共享内存段的进程数量（1 表示一个进程正在使用它）。</li><li><strong>status</strong>：共享内存的状态。</li></ul><h3 id="6-5-3-查看基本-IPC-资源信息"><a href="#6-5-3-查看基本-IPC-资源信息" class="headerlink" title="6.5.3 查看基本 IPC 资源信息**"></a>6.5.3 查看基本 IPC 资源信息**</h3><p>如果您只想获取简化的 IPC 资源统计信息，可以使用 <code>-b</code> 选项：</p><pre class="line-numbers language-bash"><code class="language-bash">ipcs -b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此命令将输出系统中所有 IPC 资源的基础信息，不会显示详细内容，但能快速提供资源使用情况。</p><h4 id="示例输出"><a href="#示例输出" class="headerlink" title="示例输出"></a><strong>示例输出</strong></h4><p>运行 <code>ipcs -b</code> 后，您可能会看到如下输出：</p><pre class="line-numbers language-bash"><code class="language-bash">plaintext------ Message Queues --------key        msqid      owner      perms      used-bytes   messages------ Shared Memory Segments --------key        shmid      owner      perms      bytes      nattch     status------ Semaphore Arrays --------key        semid      owner      perms      nsems<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-5-4-实时监控共享内存"><a href="#6-5-4-实时监控共享内存" class="headerlink" title="6.5.4 实时监控共享内存"></a>6.5.4 实时监控共享内存</h3><p>您可以结合使用 <code>watch</code> 命令，实时监控共享内存的使用情况：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">watch</span> -n 1 ipcs -m<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这将每秒更新一次共享内存段的信息，帮助您及时了解内存使用情况。</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 性能调优工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
